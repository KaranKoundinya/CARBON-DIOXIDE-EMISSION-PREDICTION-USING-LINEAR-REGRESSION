# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vILMpok72l4yjAUPY3d3w63Fv1cfzyHd

# **1.Carbon Dioxide Emission prediction using Linear Regression and an Optimisation algorithm**

### **1.1 INSTALLING LIBRARIES**
"""

!pip install -U scikit-learn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import SGDRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.metrics import r2_score
import sklearn
print(sklearn.__version__)
from sklearn.linear_model import SGDRegressor
from sklearn.model_selection import GridSearchCV
pd.set_option('max_columns', None)

"""###**1.2 DATA LOADING**"""

df = pd.read_csv('/content/MY2022 Fuel Consumption Ratings.csv')
df.head()

"""### **1.3 DATA CLEANING**

**1.2.1 Change Cases**
"""

df.shape

df.columns

df.columns = df.columns.str.upper()

df.columns

"""**1.2.2 Renaming Columns to avoid space**"""

df.rename (columns = {'MAKE' : 'BRAND' , 'MODEL YEAR': 'MODEL_YEAR' , 'VEHICLE CLASS' : 'VEHICLE_CLASS' , 'ENGINE SIZE(L)' : 'ENGINE_SIZE_L', 'FUEL TYPE' : 'FUEL_TYPE' , 'FUEL CONSUMPTION (CITY (L/100 KM)' : 'FUEL_CONSUMPTION_CITY_L/100KM' , 'FUEL CONSUMPTION(HWY (L/100 KM))' : 'FUEL_CONSUMPTION_HWY_L/100KM' , 'FUEL CONSUMPTION(COMB (L/100 KM))' : 'FUEL_CONSUMPTION_COMB_L/100KM' , 'FUEL CONSUMPTION(COMB (MPG))' : 'FUEL_CONSUMPTION_COMB_MPG' , 'CO2 EMISSIONS(G/KM)' : 'CO2_EMISSIONS' , 'CO2 RATING' : 'CO2_RATING' , 'SMOG RATING' : 'SMOG_RATING' }, inplace = True)

"""**1.2.3 Checking for missing data**"""

df.isnull()

df.isnull().any()        #columns with missing values represented in boolean terms.
                         #False means it doesn't have a missing value.

#for entire dataset 
df.isnull().any().any()

df.isnull().sum()      #number of null vaues in each column

df.isnull().sum().sum()    #getting total number of null values

"""###**1.4 DATA VISUALIZATION**




 **Q.1 Which brand is emitting the most CO2?**

  ***graph_1*** represents the categorical data *BRAND* vs *CO2 Emissions(g/km)*.

"""

plt.figure(figsize=(15,8))
graph_1 = df.groupby('BRAND')['CO2_EMISSIONS'].mean().sort_values(ascending = False).plot(x='BRAND',y='CO2_EMISSIONS',kind = 'bar')
graph_1

"""***graph_2*** is also a bar chart plotted between *BRAND* and *CO2_RATING*

"""

#low CO2 Rating means the brand emits the most CO2 out of others.
plt.figure(figsize=(15,8))
graph_2 = df.groupby('BRAND')['CO2_RATING'].mean().sort_values(ascending = False).plot(kind = 'bar')
graph_2

"""
**Q.2 Which column is in correlation with *CO2_EMISSIONS*?**

  **Q.3 Which *VEHICLE_CLASS* is more efficient?**

  ***graph_3*** shows us which *VEHICLE_CLASS* is more efficient with less number of data points and also portrays the linear relation between *CO2_EMISSIONS* and *FUEL_CONSUMPTION_COMB_L/100KM*"""

from matplotlib import pyplot as plt
import seaborn as sns    
graph_3 = sns.FacetGrid(df, col = 'VEHICLE_CLASS')
graph_3.map_dataframe(sns.scatterplot,x='CO2_EMISSIONS', y='FUEL_CONSUMPTION_COMB_L/100KM')        #click on graphs to zoom the graphs.
graph_3.set_axis_labels('CO2_EMISSIONS','FUEL_CONSUMPTION_COMB_L/100KM')
graph_3.set_titles(col_template = '{col_name}')

"""**C) What is the best Engine Size for low CO2 Emissions?**

***graph_4*** also shows the correlation between *CO2 EMISSIONS* and *FUEL_CONSUMPTION_COMB_L/100KM* with respect to their Engine Size. 
"""

graph_4 = sns.FacetGrid(df, col = 'ENGINE_SIZE_L')
graph_4.map_dataframe(sns.scatterplot,x='CO2_EMISSIONS', y='FUEL_CONSUMPTION_COMB_L/100KM')
graph_4.set_axis_labels('CO2_EMISSIONS','FUEL_CONSUMPTION_COMB_L/100KM')
graph_4.set_titles(col_template = '{col_name}')

"""**Q.4 Are all Fuel Consumption metrics correlated?**

***graph_5***, ***graph_6*** and ***graph_7*** show correlation between the Fuel Consumption metrics.
"""

graph_5 = df.plot(x="FUEL_CONSUMPTION_COMB_L/100KM", y=["FUEL_CONSUMPTION_HWY_L/100KM"], kind="scatter")
graph_5

graph_6 = df.plot(x="FUEL_CONSUMPTION_COMB_L/100KM", y=["FUEL_CONSUMPTION_CITY_L/100KM"], kind="scatter")
graph_6

graph_7 = df.plot(x="FUEL_CONSUMPTION_HWY_L/100KM", y=["FUEL_CONSUMPTION_CITY_L/100KM"], kind="scatter")
graph_7

"""*As seen above, they are correlated*

**Q.5 Which columns are correlated?**

***graph_8*** shows us the correlation between all the columns and helps us determine independent and dependent variables.
"""

df.corr()

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
# %matplotlib inline
graph_8 = sns.heatmap(df.corr(),xticklabels=True, yticklabels=True, annot=True)
graph_8

"""***graph_9*** is a joint plot and it shows us the distribution of 
*CO2 EMISSIONS* and *ENGINE SIZE* and also it helps us determine outliers.
"""

plt.figure(figsize=(12,10))
graph_9 = sns.jointplot(df['ENGINE_SIZE_L'].head(500), df['CO2_EMISSIONS'].head(500), kind='hex')
graph_9

"""**Q.6 How many outliers are there in *CO2_EMISSIONS*?**

***graph_10*** visually helps us determine the values of outliers by placing the mouse cursor.
"""

import plotly.express as px
fig = px.box(df, y="CO2_EMISSIONS")
fig.show()

"""***graph_11*** represents normal distribution of *CO2_EMISSIONS*."""

plt.figure(figsize=(12,10))
sns.distplot(df['CO2_EMISSIONS'])
plt.title("CO2_EMISSIONS is normally distributed.")

"""###**1.5 DATA PREPROCESSING**"""

#checking the datatypes
df.dtypes

#understanding categorical data and converting it into int
df.BRAND.unique()

from sklearn import preprocessing

lab_en = preprocessing.LabelEncoder()
df['BRAND'] = lab_en.fit_transform(df['BRAND'])
df['MODEL'] = lab_en.fit_transform(df['MODEL'])
df['VEHICLE_CLASS'] = lab_en.fit_transform(df['VEHICLE_CLASS'])
df['TRANSMISSION'] = lab_en.fit_transform(df['TRANSMISSION'])
df['FUEL_TYPE'] = lab_en.fit_transform(df['FUEL_TYPE'])
df

"""###**1.6 Linear Regression Model with and without SGD**

***Case -1***

In this case we have considered CO2_EMISSIONS as dependent variable and the other columns as Independent variables after eliminating Fuel consumption for City, Combined mpg and Cylinders.
"""

x=df[['MODEL_YEAR','BRAND','MODEL', 'VEHICLE_CLASS', 'ENGINE_SIZE_L','FUEL_CONSUMPTION_COMB_L/100KM', 'TRANSMISSION', 'FUEL_TYPE','CO2_RATING', 'SMOG_RATING']]
y=df[['CO2_EMISSIONS']]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)
print('shape for x_train: ',x_train.shape)
print('shape for x_test: ',x_test.shape)
print('shape for y_train: ',y_train.shape)
print('shape for y_test: ',y_test.shape)


stnsc = StandardScaler()
x_train = stnsc.fit_transform(x_train)
x_test = stnsc.fit_transform(x_test)

model = LinearRegression()
model.fit(x_train,y_train)

y_pred = model.predict(x_test)
print(
    'number of predicted values: ',y_pred.shape)

# model evaluation
print(
  'mean_squared_error : ', mean_squared_error(y_test, y_pred))
print(
  'mean_absolute_error : ', mean_absolute_error(y_test, y_pred))


#r2 score
r2_score_case1 = r2_score(y_test, y_pred)
print('r2 score for this case is ',r2_score_case1)

"""**Linear Regression with Stocastic Gradient Descent**

We will use *penalty= None* , since predictions is equal to test data.  
"""

# Tuning the SGDRegressor parameters 'eta0' (learning rate) and 'max_iter' using Grid Search
sgdr = SGDRegressor(random_state = 1, penalty = None)
grid_param = {'eta0': [.0001, .001, .01, .1, 1], 'max_iter':[10000, 20000, 30000, 40000]}
gd_sr = GridSearchCV(estimator=sgdr, param_grid=grid_param, scoring = 'r2', refit='r2', cv=5, verbose=5)
gd_sr.fit(x_train, y_train)

results = pd.DataFrame.from_dict(gd_sr.cv_results_)
print('Cross-validation results:\n', results)
 
r2_withsgd_case1 = gd_sr.best_score_
print('r2 score with Stocastic gradient decent for case 1 : ',r2_withsgd_case1)
 
best_model = gd_sr.best_estimator_
print('Intercept for case 1:' , best_model.intercept_)

coef_table = pd.DataFrame(zip(x.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False)
coef_table

plt.figure(figsize=(5,4),dpi=120)
a=coef_table['Features']
b=coef_table['Coefficients']
plt.barh(a,b)
plt.xlabel("Coefficients")
plt.ylabel("Features")

"""**Case 2**"""

x2=df.drop(columns=[ 'CO2_EMISSIONS','CYLINDERS','FUEL_CONSUMPTION_HWY_L/100KM', 'FUEL_CONSUMPTION_COMB_L/100KM'])
y2=df['CO2_EMISSIONS']


x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size = 0.3, random_state = 42)
print('shape for x2_train: ',x2_train.shape)
print('shape for x2_test: ',x2_test.shape)
print('shape for y2_train: ',y2_train.shape)
print('shape for y2_test: ',y2_test.shape)


stnsc = StandardScaler()
x2_train = stnsc.fit_transform(x2_train)
x2_test = stnsc.fit_transform(x2_test)

model = LinearRegression()
model.fit(x2_train,y2_train)

y2_pred = model.predict(x2_test)
print(
    'number of predicted values: ',y2_pred.shape)

# model evaluation
print(
  'mean_squared_error : ', mean_squared_error(y2_test, y2_pred))
print(
  'mean_absolute_error : ', mean_absolute_error(y2_test, y2_pred))


r2_score_case2 = r2_score(y2_test, y2_pred)
print('r2 score for this case is ',r2_score_case2)

"""**Case -2 with SGD Regressor**"""

# Tuning the SGDRegressor parameters 'eta0' (learning rate) and 'max_iter' using Grid Search
gd_sr.fit(x2_train, y2_train)

results = pd.DataFrame.from_dict(gd_sr.cv_results_)
print('Cross-validation results:\n', results)
 
r2_withsgd_case2 = gd_sr.best_score_
print('r2 score with Stocastic gradient decent for case 2 : ',r2_withsgd_case2)
  
best_model = gd_sr.best_estimator_
print('Intercept for case 2:' , best_model.intercept_)

coef_table2 = pd.DataFrame(zip(x.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False)
coef_table

plt.figure(figsize=(5,4),dpi=120)
a2=coef_table['Features']
b2=coef_table['Coefficients']
plt.barh(a2,b2)
plt.xlabel("Coefficients")
plt.ylabel("Features")

"""**Case -3**"""

x3=df.drop(columns='CO2_EMISSIONS')
y3=df[['CO2_EMISSIONS']]
x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size = 0.3, random_state = 42)
print(x3_train.shape)
print(x3_test.shape)
print(y3_train.shape)
print(y3_test.shape)
 
x3_train.mean()

stnsc = StandardScaler()
x3_train = stnsc.fit_transform(x3_train)
x3_test = stnsc.fit_transform(x3_test)


model = LinearRegression()
model.fit(x3_train,y3_train)

y3_pred = model.predict(x3_test)
print(y3_pred.shape)


# model evaluation
print(
  'mean_squared_error : ', mean_squared_error(y3_test, y3_pred))
print(
  'mean_absolute_error : ', mean_absolute_error(y3_test, y3_pred))


r2_score_case3 = r2_score(y3_test, y3_pred)

print(r2_score_case3)

"""**Case -3 with SGD Regressor**"""

gd_sr.fit(x3_train, y3_train)

results = pd.DataFrame.from_dict(gd_sr.cv_results_)
print('Cross-validation results:\n', results)
 
r2_withsgd_case3 = gd_sr.best_score_
print('r2 score with Stocastic gradient decent for case 3 : ',r2_withsgd_case3)
  
best_model = gd_sr.best_estimator_
print('Intercept for case 3:' , best_model.intercept_)

coef_table3 = pd.DataFrame(zip(x.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False)
coef_table

plt.figure(figsize=(5,4),dpi=120)
a2=coef_table['Features']
b2=coef_table['Coefficients']
plt.barh(a2,b2)
plt.xlabel("Coefficients")
plt.ylabel("Features")

"""###**1.7 Comparing**"""

R2_SCORE_withoutSGD = [r2_score_case1,r2_score_case2,r2_score_case3]
R2_SCORE_withSGD = [r2_withsgd_case1,r2_withsgd_case2,r2_withsgd_case3]

col={'Linear Regression':R2_SCORE_withoutSGD,'Stocastic Gradient Descent':R2_SCORE_withSGD}
cases=['Case 1','Case 2','Case 3']

f=pd.DataFrame(data=col,index=cases)
f

"""*the whole notebook takes 1:24 minutes to run*"""